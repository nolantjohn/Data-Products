rev <- gsub(",","",gdp$V5)
View(rev)
class(rev[2])
mean(numeric(gdp$V5), na.rm=T)
mean(numeric(rev), na.rm=T)
mean(rev, na.rm=T)
rev <- str_trim(rev)
rev <- as.numeric(rev)
View(rev)
mean(rev, na.rm=T)
max(rev)
rev <- na.omit(rev)
View(rev)
rev2 <- rev[1:190]
View(rev2)
mean(rev2, na.rm=T)
grep("^United",gdp$V4)
country <- read.csv("C:/Users/nolantj/Desktop/Data Science/Coursera DS/Get & Clean Data/Quiz 4/getdata-q4-EDSTATS_Country.csv")
View(country)
country(names)
names(country)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(sampleTimes)
tail(sampleTimes)
sampleTimes[2000]
View(sampleTimes[1000:2000])
View(sampleTimes[1262:1511])
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
summrry(temp)
summary(temp)
mean(temp)
x <- c(0.18, -1.54, 0.42, 0.95)
a <- .0025
b <- .1471
c <- b
b <- 1.077
d <- .300
l <- a - x
l
sum(l)
l2 <- b - x
sum(l2)
w <- c(2, 1, 3, 1)
l <- l^2
l
l <- w * l
l <- sum(l)
l
l2 <- l2^2
l2 <- l2*w
l2 <- sum(l2)
l2
l2 <- c - x
l2 <- l2^2
l2 <- l2*w
l2 <- sum(l2)
l2
l2 <- d - x
l2 <- l2^2
l2 <- l2*w
l2 <- sum(l2)
l2
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
8.58-9.31
data.Normalization (x,type="n1",normalization="column")
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(y, x) *  sd(y) / sd(x)
beta1
g <- data(mtcars)
g
data(mtcars)
library(datasets)
g <- data(mtcars)
data(mtcars)
mtcars
rm(g)
y <- mtcars$mpg
x <- mtcars$weight
beta1 <- cor(y, x) *  sd(y) / sd(x)
y
x
x <- mtcars$wt
beta1 <- cor(y, x) *  sd(y) / sd(x)
beta1
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x))/sd(x)
xn
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(y, x) *  sd(y) / sd(x)
beta1
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
library()
library(knitr)
install.packages("knitr")
library(knitr)
library()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
install.packages("ggplot2")
library(ggplot2)
q <- Qplot(CompressiveStrength, row.names, colour=names(training), data=training)
q <- qplot(CompressiveStrength, row.names, colour=names(training), data=training)
q+geom_smooth(method='lm',formula=y~x)
q <- qplot(CompressiveStrength, row.names, data=training)
q+geom_smooth(method='lm',formula=y~x)
q <- qplot(CompressiveStrength, 'row.names', data=training)
str(q)
q+geom_smooth(method='lm',formula=y~x)
show(q)
show()
names(show())
summary(show())
summary(show)
summary(training$Superplasticizer)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
skewness(log(training$Superplasticizer))
library(e1071)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
packageVersion("swirl")
library(swirl)
install_from_swirl("Statistical Inference")
install_from_swirl("Regression Models")
swirl()
11/12
deck
52
4/52
0
12/52
2/51
1.6
.64
.64/1
mypdf
integrate(mypdf, lower=0, upper=1.6)
srt(.5/4)
sqrt(.5/4)
sqrt(2)
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
3
21/6
expect_dice()
summary(expect_dice())
summary(expect_dice)
str(expect_dice
)
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
.5*(edh+edl)
integrate(myfunc, lower=0,upper=2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smeans)
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline,
| lwd=3, col='red')
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope,ols.ic))
all.equal(varChild, (varRes+varEst))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit)
mean(efit$residuals)
cov(mean(attenu$mag)
cov(attenu$mag)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cov(gpa_nor, gch_nor)
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
ppois(10, lambda = 5*3)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
lm(x ~ y)
lm(y ~ x)
l <- lm(y ~ x)
summary(l)
datasets::mtcars
mt <- datasets::mtcars
l <- lm(mt$mpg ~ mt$wt)
summary(l)
l.
l$.
"."
?mtcars
l
library(swirl)
swirl()
fit <- lm(child ~ parent, data = galton)
exit()
exit
0
1100 + c(-1,1)*qt(.95, 8)*30/sqrt(9)
-2 + c(-1,1)*qt(.95, 8)*2.1/sqrt(9)
-2 + c(-1,1)*qt(.95, 8)*2.6/sqrt(9)
-2 + c(-1,1)*qt(.95, 8)*1.5/sqrt(9)
-2 + c(-1,1)*qt(.95, 8)*.3/sqrt(9)
diff <- 3 - 5
s <- sd(diff)
t.test(5, 3)
t.test(diff)
t.test(3 - 5)
x <- rep(3, 9)
y <- rep (5, 9)
dif <- x-y
t.test(dif)
library(swirl)
swirl()
3.5
expect_dice
quit()
library(swirl)
swirl()
library
library()
library(jpeg)
library(jpg)
swirl()
10 * .8^3*.2^2
10 * .8^1*.2^4
choose(5,3)*(.8)^3*(.2)^(5-3)+choose(5,4)*(.8)^4*(.2)^(5-4)+choose(5,5)*(.8)^5*(.2)^(5-5)
n
5
pbinom(2,size=5,prob=.8,lower.tail=FALSE)
qnorm(.1)
0
qnorm(.972, mean = 3, sd = sqrt(4))
qnorm(.975, mean = 3, sd = sqrt(4))
qnorm(.975, mean = 3, sd = 2)
3 + 1.96*2
9
pnorm(1200,mean=1020,sd=50,lower.tail=FALSE)
9
pnorm((1200-1020)/50,lower.tail=FALSE)
pnorm(.75,mean=1020,sd=50)
qnorm(.75,mean=1020,sd=50)
pnorm(qnorm(.53))
qnorm(pnorm(.53))
5
ppois(3,2.5 * 4)
5
pbinom(5,1000,.01)
9
ppois(5,1000*.01)
q()
data(mtcars)
fit <- lm(mpg ~ I(wt - mean(wt)), data = mtcars)
fit
?predict
predict(fit, 3000)
confint(fit)
fit2 <- lm(mpg ~ 3000, data = mtcars)
fit2 <- lm(mpg ~ wt, data = mtcars)
confint(fit2)
plot(mpg ~ wt, data = mtcars)
plot(mpg ~ I(wt - mean(wt)), data = mtcars)
plot(lm(mpg ~ I(wt - mean(wt)), data = mtcars))
predict(lm(mpg ~ I(wt - mean(wt)), data = mtcars), new = 3000)
predict(lm(mpg ~ I(wt - mean(wt)), data = mtcars), 3000)
plot(fit)
new <- 3000
lm(fit, new = data.frame(mtcars = new))
fit2 <- lm(fit, new = data.frame(mtcars = new))
confint(fit2)
confint(lm(fit, new = data.frame(mtcars = new)))
lm(fit, new = data.frame(mtcars = new))
fit2 <- lm(fit, newdata = data.frame(mtcars = new))
fit2 <- predict(fit, newdata = data.frame(mtcars = new))
fit2 <- predict(lm(mpg ~ I(wt - mean(wt)), data = mtcars), newdata = data.frame(mtcars = new))
mean(mtcars$wt)
summary(mtcars$wt)
summary(mtcars$mpg)
new <- 3
fit2 <- predict(lm(mpg ~ I(wt - mean(wt)), data = mtcars), data.frame(mtcars = new))
fit <- lm(mpg ~ I(wt - mean(wt)), data = mtcars)
fit2 <- predict(fit, data.frame(new))
new <- data.frame(x=3000/1000)
fit2 <- predict(fit, new)
fit <- lm(mpg ~ wt, data = mtcars)
predict(fit, newdata = data.frame(wt = 3))
fit <- lm(mpg ~ wt, data = mtcars)
predict(fit, newdata = data.frame(wt = 3), interval = "prediction")
fit <- lm(mpg ~ I(wt * .5, data = mtcars)
)
fit <- lm(mpg ~ I(wt * .5), data = mtcars)
confint(fit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p = .75)
training <- segmentationOriginal[inTrain,]
inTrain <- createDataPartition(y=segmentationOriginal$Case, p = .75, list=F)
training <- segmentationOriginal[inTrain,]
set.seed(125)
mod <- train(segmentationOriginal~., method="rpart", data=training)
mod <- train(data.frame(segmentationOriginal)~., method="rpart", data=training)
data.frame(segmentationOriginal)
segmentationOriginal <- data.frame(segmentationOriginal)
mod <- train(segmentationOriginal~., method="rpart", data=training)
View(training)
mod <- train(Case~., method="rpart", data=training)
install.packages("e1071")
mod <- train(Case~., method="rpart", data=training)
plot(mod$finalModel, uniform=T)
text(mod$finalModel, use.n=T, all=T, cex=.8)
print(mod$finalModel)
mod
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
mod <- train(Area~., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
l = .2
tmean = 1/l
tvar = (1/l)^2
sim = 1000
navg = 40
rexp(n = navg, lambda = l)
rexp(n = navg, l)
hist(rexp(n = navg, l))
emean = NULL
for (i in 1:sim) emean = c(emean, mean(rexp(n = navg, l)))
hist(emean)
mean(emean)
print("The: ", tmean)
print(paste("The: ", tmean, sep = ","))
print(paste("The: ", tmean))
print(paste("The:", tmean))
print(c("The: ", tmean))
var(emean)
sd(emean)
r <- rexp(n = sim, l)
sd(r)
var(r)
mean(r)
r <- runif(1000)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
mean(mns)
mean(r)
var(mns)
var(r)
var(r)/40
25/40
hist(var(emean))
plot(emean)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.test)
class(vowel.test$y)
vowel.test$y <- factor(vowel.test$y)
class(vowel.test$y)
head(vowel.test)
vowel.train$y <- factor(vowel.train$y)
set.seed(33833)
library(caret)
set.seed(33833)
rf <- train(y~.,data = vowel.train,method = "rf", prox = T)
prf <- predict(rf,vowel.test)
prf
table(prf,vowel.test$y)
confusionMatrix(prf,vowel.test$y)
b <- train(y~.,data = vowel.train,method = "gbm", verbose = F)
pb <- predict(b,vowel.test)
confusionMatrix(pb,vowel.test$y)
install.packages("agreement")
install.packages("Agreement")
library(Agreement)
agreement(prf,pb, vowel.test)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf <- train(diagnosis~.,data = training,method = "rf", prox = T)
b <- train(diagnosis~.,data = training,method = "gbm", verbose = F)
l <- train(diagnosis~.,data = training,method = "lda")
prf <- predict(rf,testing)
pb <- predict(b,testing)
pl <- predict(l,testing)
df <- data.frame(prf,pb,pl, diagnosis=testing$diagnosis)
c <- train(diagnosis~.,method = "rf", data = df)
pc <- predict(c,df)
confusionMatrix(pc,testing$diagnosis)
confusionMatrix(prf,testing$diagnosis)
confusionMatrix(pb,testing$diagnosis)
confusionMatrix(pl,testing$diagnosis)
confusionMatrix(pc,df$diagnosis)
datasets::mtcars
datasets(mtcars)
library(mtcars)
mtcars
mtcars <- mtcars
one <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
coef(one)
summary(one)$coef
two <- lm(mpg ~ factor(cyl), data = mtcars)
summary(two)$coef
?mtcars
o <- lm(mpg ~ wt + factor(cyl), data = mtcars)
summary(o)$coef
o <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(o)$coef
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
round(dfbetas(fit), 2)
round(hatvalues(fit), 2)
?shuttle
data("shuttle")
shuttle
one <- glm(use~wind, data = shuttle, family = "binomial")
summary(one)
-.25131/-.03181
exp(one$coefficients)
one <- glm(use~wind+magn, data = shuttle, family = "binomial")
exp(one$coefficients)
data(InsectSprays)
head(InsectSprays)
four <- glm(count~factor(spray), data = InsectSprays, family = poisson)
exp(four$coefficients)
four$coefficients
setwd("C:/Users/nolantj/Desktop/Data Science/Coursera DS/Data Products/GenGuess")
shiny::runApp()
shiny::runApp(display.mode = "showcase")
